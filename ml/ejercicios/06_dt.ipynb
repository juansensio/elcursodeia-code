{"cells":[{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/elcursodeia-code/blob/master/ml/ejercicios/06_dt.ipynb)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fS4SXdycrJe6"},"source":["# Ejercicio: Crea un bosque de árboles de decisión"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{},"colab_type":"code","id":"4x8jo2eDsrCU"},"outputs":[],"source":["import numpy as np\n","\n","def plot_moons(X, y):\n","  plt.plot(X[y == 0][:, 0], X[y == 0][:, 1], '.r')\n","  plt.plot(X[y == 1][:, 0], X[y == 1][:, 1], '.b')\n","  plt.xlabel(r\"$x_1$\", fontsize=18)\n","  plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n","  plt.title(f'Samples: 0 - {np.sum(y == 0)} 1 - {np.sum(y == 1)} ')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_pidfs_ArTU7"},"source":["## 1. Genera los datos\n"," \n","Utiliza 10000 muestras con un ruido de 0.4"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"colab_type":"code","executionInfo":{"elapsed":1889,"status":"ok","timestamp":1583941481239,"user":{"displayName":"Juan B. Pedro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWgAzHaZEfUQ37UFPks7-k3-muJ6YMlGogBy-2JA=s64","userId":"14564361589067109105"},"user_tz":-60},"id":"a8uzG3d-rFlw","outputId":"8707eac4-3b75-4e4d-877e-ea8d5ad9ad31"},"outputs":[],"source":["from sklearn.datasets import make_moons\n","import matplotlib.pyplot as plt\n","\n","# tu código aquí"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ml2KDYFTsgro"},"source":["## 2. Separa los datos en conjuntos de entrenamiento y test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# tu código aquí"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_OntVRsRta_R"},"source":["## 3. Entrena un árbol de decisión\n","\n","Utiliza búsqueda en cuadrícula con validación cruzada (con la ayuda de la clase GridSearchCV) para encontrar buenos valores de hiperparámetros para un DecisionTreeClassifier. ¿Qué precisión puedes lograr?\n","\n","Pista: prueba varios valores para max_leaf_nodes."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"colab_type":"code","executionInfo":{"elapsed":13696,"status":"ok","timestamp":1583941554551,"user":{"displayName":"Juan B. Pedro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWgAzHaZEfUQ37UFPks7-k3-muJ6YMlGogBy-2JA=s64","userId":"14564361589067109105"},"user_tz":-60},"id":"-5uGKUe2taTK","outputId":"66922403-2237-4011-ea3c-f09841bc5d12"},"outputs":[],"source":["# tu código aquí"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B9wUYAzTuCM8"},"source":["## 4. Crea un bosque"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FXCtzrBLuJJj"},"source":["### 4.1 Genera datos de entrenamiento\n","\n","Genera 1000 subconjuntos del conjunto de entrenamiento, cada uno conteniendo 100 muestras aleatorias."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{},"colab_type":"code","id":"W7mU-LHdt9VJ"},"outputs":[],"source":["from sklearn.model_selection import ShuffleSplit\n","\n","# tu código aquí"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"68dANDtfu5-b"},"source":["## 4.2 Entrena un árbol de decisión para cada subconjunto\n","\n","Entrena un Árbol de Decisión en cada subconjunto, utilizando los mejores valores de hiperparámetros encontrados anteriormente. Evalúa estos 1,000 Árboles de Decisión en el conjunto de prueba. Dado que fueron entrenados en conjuntos más pequeños, es probable que estos Árboles de Decisión tengan un rendimiento peor que el primer Árbol de Decisión."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1774,"status":"ok","timestamp":1583944177560,"user":{"displayName":"Juan B. Pedro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWgAzHaZEfUQ37UFPks7-k3-muJ6YMlGogBy-2JA=s64","userId":"14564361589067109105"},"user_tz":-60},"id":"vjDVVpUZugxw","outputId":"e877ad5a-8b48-4263-e6a3-a64afe6cfbbd"},"outputs":[],"source":["# tu código aquí"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sZ7HMTbpvP0B"},"source":["## 4.3 Modelo ensamblado\n","\n","Ahora viene la magia. Para cada instancia del conjunto de prueba, genera las predicciones de los 1,000 Árboles de Decisión, y conserva solo la predicción más frecuente (puedes usar la función mode() de SciPy para esto). Esto te da predicciones por voto mayoritario sobre el conjunto de prueba. ¿Es la precisión final mejor que la de nuestro Árbol de Decisión?"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{},"colab_type":"code","id":"RdN1ic_nvMHG"},"outputs":[],"source":["from scipy.stats import mode\n","\n","# tu código aquí"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vnccxUZNvrO7"},"source":["¡Felicidades, has entrenado un clasificador de Random Forest!"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"6_decision_trees_solution.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}
